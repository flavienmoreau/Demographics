{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2001,
     "status": "ok",
     "timestamp": 1739920928994,
     "user": {
      "displayName": "Eric Huang",
      "userId": "05854437199620858461"
     },
     "user_tz": 300
    },
    "id": "SMAj_KCkJvQ3",
    "outputId": "9ff4501f-659e-407f-db51-50bff210c60d"
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "os.chdir('\\\\\\\\Data1\\\\RES1\\\\WRK\\\\CHT\\\\w2025weo\\\\Ch3-Demographics\\\\Code_Review\\\\EH') # change the directory to your own\n",
    "\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import copy, pickle, time\n",
    "from Code import ss as steady_state, td as transition, jacobians as jac\n",
    "from Code.calibration import load_initial_ss\n",
    "from Code import production, government, demographics, household, equilibrium, calibration\n",
    "from Code.gen_h_mult import gen_h_mult\n",
    "\n",
    "# from importlib import reload\n",
    "# from model import td as transition\n",
    "# reload(transition)\n",
    "\n",
    "path_data_inputs = \"@Import/Data/input_data/\"\n",
    "path_intermediate_data = \"@Import/Data/intermediate_data/\"\n",
    "path_calibration_targets = \"@Import/Data/calibration_targets/\"\n",
    "path_calibrated_parameters = \"@Import/Data/calibrated_parameters/\"\n",
    "path_cached_results = \"@Import/Data/cached_results/\"\n",
    "path_model_outputs = \"@Export/output_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4QVjMYkkTFlk"
   },
   "source": [
    "Set up parameters indicating the scenario we want to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1739920928994,
     "user": {
      "displayName": "Eric Huang",
      "userId": "05854437199620858461"
     },
     "user_tz": 300
    },
    "id": "8IZGJq3nTEWY"
   },
   "outputs": [],
   "source": [
    "migration = False                             # whether there's additional migration from LIC (True or False)\n",
    "closed_economy = None                         # which country to simulate in financial autarky (None or 'LIC')\n",
    "h_mult_scenario = 'Baseline'                  # the h_mult scenario ('Baseline' or 'Innovation' or 'Healthy aging' or 'Baseline_morehealth' or 'FLFP' or 'All' (closing FLFP gap & more health) or 'Demog_only' or 'No_innovation')\n",
    "LIC_wedge = 0.03                              # the wedge applied to LIC's interest rate (percent / 100)\n",
    "fertility_scenario = 'medium'                 # UNPP fertility scenario ('low', 'medium', or 'high')\n",
    "alt_debt = False                              # whether debt level returns to the 16-19 average (True or False)\n",
    "alt_ret = False                               # whether to run the retirement policy scenario (True or False)\n",
    "FLFP_gap = None                               # by how much FLFP gap closes by 2040 (in percent): None, 50, 75, or 100\n",
    "vintage_UNPP = False                          # whether to use vintage UNPP (True or False)\n",
    "sigma = 2                                     # 1 / IES; default is 2\n",
    "\n",
    "LIC_integration = 'baseline'                  # the speed of LIC financial integration: 'faster', 'slower', or 'baseline'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQnjW5lWvO3J"
   },
   "source": [
    "Construct calibration targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1739920928995,
     "user": {
      "displayName": "Eric Huang",
      "userId": "05854437199620858461"
     },
     "user_tz": 300
    },
    "id": "Ni65lWS0mkCQ"
   },
   "outputs": [],
   "source": [
    "from Code import isocode\n",
    "cs_full = sorted(isocode.isocode_list_full)\n",
    "cs_full.append('LIC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1739920928995,
     "user": {
      "displayName": "Eric Huang",
      "userId": "05854437199620858461"
     },
     "user_tz": 300
    },
    "id": "PpriqZeFtins"
   },
   "outputs": [],
   "source": [
    "df_w = pd.read_csv(path_calibration_targets + \"targets_global.csv\")\n",
    "\n",
    "if df_w.loc[0,'sigma'] != sigma:\n",
    "\n",
    "  df_w.loc[0,'sigma'] = sigma\n",
    "  df_w.to_csv(path_calibration_targets + \"targets_global.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZR3Kt60-wEjG"
   },
   "source": [
    "Calibrate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "l8OUJNpuwGLG"
   },
   "outputs": [],
   "source": [
    "recalibrate = True\n",
    "\n",
    "suffix = '_mig' if migration is True else ''\n",
    "suffix += '_autarky' if closed_economy is not None else ''\n",
    "suffix += '_' + h_mult_scenario.replace(\" \", \"_\") if h_mult_scenario != 'Baseline' else ''\n",
    "suffix += '_FLFP' + str(FLFP_gap) if FLFP_gap is not None else ''\n",
    "suffix += f\"_{fertility_scenario}\" if fertility_scenario != \"medium\" else \"\"\n",
    "suffix += '_altdebt' if alt_debt is True else ''\n",
    "suffix += '_altret' if alt_ret is True else ''\n",
    "suffix += '_vintage_UNPP' if vintage_UNPP is True else ''\n",
    "suffix += f'_IES{sigma}' if sigma != 2 else ''\n",
    "\n",
    "if recalibrate:\n",
    "  if not os.path.exists(path_calibrated_parameters + f\"params_calib{suffix}.csv\"):    #\"params_calib_LIC_w_gamma_varBY3.csv\"\n",
    "    df_calib = calibration.calib_ss(case='homothetic', LIC_wedge=LIC_wedge)\n",
    "    df_calib.to_csv(path_calibrated_parameters + f\"params_calib{suffix}.csv\")\n",
    "  else:\n",
    "    shutil.copy2(path_calibrated_parameters + f\"params_calib{suffix}.csv\",\n",
    "                path_calibrated_parameters + \"params_calib_homothetic_varyxi.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWEvHsvFzpXY"
   },
   "source": [
    "Load objects from the calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ci0u9Cc9wvjQ"
   },
   "outputs": [],
   "source": [
    "# Initial steady state\n",
    "r_init, gamma, hh_init, prod_init, pop_init, gov_init, ss_init = load_initial_ss(case='homothetic', LIC_wedge=LIC_wedge)\n",
    "J = len(hh_init['USA'].h_adj)                                         # number of age bins\n",
    "\n",
    "# Keep only one country if need to run the autarky scenario\n",
    "if closed_economy is not None:\n",
    "  for var_name in ['hh_init', 'prod_init', 'pop_init', 'gov_init', 'ss_init']:\n",
    "    globals()[var_name] = {k: v for k, v in globals()[var_name].items() if k in [closed_economy]}\n",
    "    r_init += LIC_wedge\n",
    "\n",
    "cs = list(hh_init)                                                    # ISO code list for the countries in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHahGMI60d9P"
   },
   "source": [
    "Our standard exogenous shifters: government and population (need both terminal and transition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "hQR2wZxfZE6a"
   },
   "outputs": [],
   "source": [
    "# Population shifter based on targets on the transition path (\"targets_trans_countries***.csv\")\n",
    "pop = demographics.load_poptrans(migration=migration, closed_economy=closed_economy,\n",
    "                                 fertility_scenario=fertility_scenario,vintage_UNPP=vintage_UNPP)\n",
    "\n",
    "T = len(pop['LIC'].N)                                                 # number of years in the transition\n",
    "pop_term = {c: pop[c].get_ss_terminal() for c in cs}                  # terminal population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "k-91zvSQyJR0"
   },
   "outputs": [],
   "source": [
    "# Government shifter\n",
    "\n",
    "# Import B/Y paths\n",
    "B_Y_path = pd.read_csv(\"@Import/Data/intermediate_data/debt_gdp_w_LIC.csv\")\n",
    "year_max, year_min = B_Y_path['year'].max(), B_Y_path['year'].min()\n",
    "num_years = year_max - year_min + 1\n",
    "B_Y_end = B_Y_path.query('year == @year_max').set_index('isocode')['debt_gdp']                          # B/Y in the last year of the data provided (2029)\n",
    "B_Y_16_19 = B_Y_path.query('@year_min <= year <= @year_min+3').groupby('isocode')['debt_gdp'].mean()    # average B/Y between 2016-19\n",
    "years_to_extend = range(year_max+1, year_max+1+T+1-num_years)\n",
    "slope = (B_Y_16_19 - B_Y_end) / 10                                                                      # the slope of an alternative B/Y path returning to the 16-19 avg in 10 years\n",
    "\n",
    "# Fill the B/Y path between 2030 and 2400\n",
    "new_rows = []\n",
    "for country in B_Y_path['isocode'].unique():\n",
    "    for year in years_to_extend:\n",
    "        # Stay at the 2029 B/Y level if using the baseline path, or if the 2029 level <= the 2016-19 avg\n",
    "        if not alt_debt or B_Y_end[country] <= B_Y_16_19[country]:\n",
    "            new_rows.append([country, year, B_Y_end[country]])\n",
    "\n",
    "        # Otherwise, decrease linearly to the 2016-19 avg\n",
    "        else:\n",
    "            B_Y_curr = max(B_Y_end[country] + slope[country] * (year - year_max), B_Y_16_19[country])\n",
    "            new_rows.append([country, year, B_Y_curr])\n",
    "\n",
    "B_Y_extended = pd.DataFrame(new_rows, columns = B_Y_path.columns.to_list())\n",
    "B_Y_final = pd.concat([B_Y_path, B_Y_extended], ignore_index=True).sort_values(by=['isocode', 'year']).set_index('isocode')\n",
    "\n",
    "# Import retirement age paths\n",
    "ret_path = pd.read_excel(\"@Import/Data/intermediate_data/_Tr_Scenario1.xlsx\")[['isocode','year','Tr_1']]\n",
    "year_max, year_min = ret_path['year'].max(), ret_path['year'].min()\n",
    "ret_max = ret_path.query('year == @year_max').set_index('isocode')['Tr_1']\n",
    "ret_min = ret_path.query('year == @year_min').set_index('isocode')['Tr_1']\n",
    "ret_increase = ret_max - ret_min\n",
    "years_to_extend = range(year_max+1, 2401)\n",
    "\n",
    "# Fill the retirement age path between 2101 and 2400\n",
    "for country in ret_path['isocode'].unique():\n",
    "  for year in years_to_extend:\n",
    "    ret_path = pd.concat([ret_path,\n",
    "      pd.DataFrame([[country, year, ret_max[country]]], columns=ret_path.columns.to_list())])\n",
    "\n",
    "ret_path = ret_path.sort_values(by=['isocode', 'year']).set_index('isocode')\n",
    "\n",
    "# Construct the government shifter\n",
    "gov = {}\n",
    "gov_term = copy.deepcopy(gov_init)\n",
    "for c in cs:\n",
    "    B_Y_curr = B_Y_final.loc[c,'debt_gdp'].to_list()\n",
    "    if alt_ret:\n",
    "      ret_curr = ret_path.loc[c,'Tr_1'].to_list()\n",
    "      gov[c] = gov_init[c].ss_to_td(T, B_Y=B_Y_curr, ret_path=ret_curr)\n",
    "    elif c in ('LIC', 'IND'):\n",
    "      gov[c] = gov_init[c].ss_to_td(T, B_Y=B_Y_curr)\n",
    "    else:\n",
    "      gov[c] = gov_init[c].ss_to_td(T, age_increase=5, years_increase=60, B_Y=B_Y_curr)\n",
    "\n",
    "    gov[c].adjust_rule = 'all'\n",
    "\n",
    "    gov_term[c].adjust_rule = 'all'\n",
    "    years_adj = (5 if not alt_ret and c not in ('LIC', 'IND')\n",
    "                else 0 if not alt_ret and c in ('LIC', 'IND')\n",
    "                else ret_increase[c])\n",
    "    gov_term[c].rho = gov_term[c].adjust_rho(gov_term[c].rho, years_adj)\n",
    "\n",
    "# Update B_Y for the gov object\n",
    "gov_term = {c: gov_term[c].update_B_Y(B_Y_end[c]) for c in gov_term}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_iESLbK2UQG"
   },
   "source": [
    "Now we have a new shifter to the household labor supply, which leads to a new terminal steady state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "yAUoaPZu2VGe"
   },
   "outputs": [],
   "source": [
    "FE_dta = pd.read_excel(path_intermediate_data + \"_Input_For_MODEL.xlsx\").set_index('iso3code')\n",
    "\n",
    "# Average out the FEs for CHN and IND\n",
    "avg_CHN_IND = (FE_dta.loc['CHN']['_cons_fe'] + FE_dta.loc['IND']['_cons_fe']) / 2\n",
    "FE_dta.loc['CHN','_cons_fe'] = avg_CHN_IND\n",
    "FE_dta.loc['IND','_cons_fe'] = avg_CHN_IND\n",
    "\n",
    "# Fixed effects\n",
    "FE_convergence = {c: FE_dta.loc[c]['_cons_fe'] if c != 'USA' else 0 for c in cs_full}\n",
    "beta_conv = FE_dta.loc['AUS']['_beta_distance']\n",
    "beta_pop = FE_dta.loc['AUS']['_beta_demo']\n",
    "beta_pop_lag = FE_dta.loc['AUS']['_beta_demolag']\n",
    "beta_inter = FE_dta.loc['AUS']['_beta_interac']\n",
    "\n",
    "h_mult_mtx = gen_h_mult(case=h_mult_scenario,beta_conv=beta_conv,beta_pop=beta_pop,\n",
    "                        beta_pop_lag=beta_pop_lag,beta_inter=beta_inter,FE_conv=FE_convergence,\n",
    "                        FLFP_gap=FLFP_gap,LIC_wedge=LIC_wedge,migration=migration,\n",
    "                        vintage_UNPP=vintage_UNPP,fertility_scenario=fertility_scenario)\n",
    "\n",
    "h_mult = {h_mult_scenario: h_mult_mtx}\n",
    "\n",
    "# Update the terminal hosuehold object with the terminal h_mult matrix\n",
    "hh_term = {c: hh_init[c].update_h(h_mult_mtx[c][-1]) for c in cs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UIc48QxB15_P"
   },
   "source": [
    "Calculate terminal interest rate and other objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "e3m0YG7o1TnF"
   },
   "outputs": [],
   "source": [
    "r_term = steady_state.solve_world_ss(hh_term, pop_term, gov_term, prod_init, gamma, rmin=0, rmax=0.036)\n",
    "\n",
    "# Store the terminal interest rate in the specified CSV file, which will be used by calculate_terminal_fakenews()\n",
    "cached_r_term = {'Autarky': r_term} if closed_economy is not None else {'Baseline': r_term}\n",
    "pd.DataFrame(list(cached_r_term.items())).to_csv(\"@Import/Data/cached_results/cached_r_terms.csv\", index=False, header=False)\n",
    "\n",
    "ss_term, prod_term = {}, {}\n",
    "for c in cs:\n",
    "    ss_term[c], _, prod_term[c] = steady_state.calculate_ss(\n",
    "        hh_term[c], pop_term[c], gov_term[c], prod_init[c], r_term, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hnH0uXwVHg3z"
   },
   "source": [
    "Calculate the terminal fake news matrix for transition simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "mZFSGdzIHXWF"
   },
   "outputs": [],
   "source": [
    "fixed_debt = True if np.isscalar(gov['LIC'].B_Y) else False\n",
    "\n",
    "suffix = '_mig' if migration is True else ''\n",
    "suffix += '_autarky' if closed_economy is not None else ''\n",
    "suffix += '_' + h_mult_scenario.replace(\" \", \"_\") if h_mult_scenario != 'Baseline' else ''\n",
    "suffix += '_FLFP' + str(FLFP_gap) if FLFP_gap is not None else ''\n",
    "suffix += f\"_{fertility_scenario}\" if fertility_scenario != \"medium\" else \"\"\n",
    "suffix += '_altdebt' if alt_debt is True else ''\n",
    "suffix += '_altret' if alt_ret is True else ''\n",
    "suffix += '_vintage_UNPP' if vintage_UNPP is True else ''\n",
    "suffix += f\"_{LIC_integration}_integration\" if LIC_integration != \"baseline\" else ''\n",
    "suffix += '_baseline' if suffix == '' else ''\n",
    "suffix += f'_IES{sigma}' if sigma != 2 else ''\n",
    "\n",
    "common_args = {\n",
    "    'h_mult': h_mult,\n",
    "    'calibration_options': {'case': 'homothetic'},\n",
    "    'fixed_debt': fixed_debt,\n",
    "    'migration': migration,\n",
    "    'closed_economy': closed_economy,\n",
    "    'fertility_scenario': fertility_scenario,\n",
    "    'alt_debt': alt_debt,\n",
    "    'alt_ret': alt_ret,\n",
    "    'FLFP_gap': FLFP_gap,\n",
    "    'vintage_UNPP': vintage_UNPP,\n",
    "    'LIC_wedge': LIC_wedge,\n",
    "    'sigma': sigma,\n",
    "    'LIC_integration': LIC_integration\n",
    "}\n",
    "\n",
    "Fs = jac.calculate_terminal_fakenews(**common_args)\n",
    "\n",
    "Jhh = ({c: jac.make_household_jacobian(Fs[c], r_term, ss_term[c]['W'], hh_term[c],\n",
    "      gov_term[c], pop_term[c], prod_term[c], T) for c in prod_term})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0u1hhWnUSO5o"
   },
   "source": [
    "Compute the entire transition path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "fnoN4ZqOJ-pz"
   },
   "outputs": [],
   "source": [
    "#cs_small = ['USA', 'CHN', 'JPN', 'LIC', 'DEU'] #, 'IND'] # smaller set of countries to speed up\n",
    "tol = 1e-5 if closed_economy is not None else 1e-4\n",
    "\n",
    "r, W_Y, NFA_Y, K_Y, Y, PB_Y, C_Y, Inc_Y, G_Y, tau, d_bar = transition.solve_world_td_full(\n",
    "    pop, gov, r_term, ss_term, cs=cs, tol=tol, **common_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "CCUEiGuf4i2a"
   },
   "outputs": [],
   "source": [
    "save_soe = False\n",
    "\n",
    "if save_soe or suffix == '_baseline' or (h_mult_scenario == 'All' and sigma == 2):\n",
    "  r_soe = {c: np.full(T, r_init) if c not in ('CHN','IND','LIC') else np.full(T, r_init) + LIC_wedge for c in cs}\n",
    "  W_Y_soe, NFA_Y_soe, K_Y_soe, Y_soe, PB_Y_soe, C_Y_soe, Inc_Y_soe, G_Y_soe, tau_soe, d_bar_soe = {}, {}, {}, {}, {}, {}, {}, {}, {}, {}\n",
    "\n",
    "  hh_td = {c: hh_init[c].update_h(h_mult_mtx[c]) for c in cs}\n",
    "  for c in cs:\n",
    "    (W_Y_soe[c], NFA_Y_soe[c], K_Y_soe[c], Y_soe[c], PB_Y_soe[c], C_Y_soe[c],\n",
    "     Inc_Y_soe[c], G_Y_soe[c], tau_soe[c], d_bar_soe[c]) = (\n",
    "        transition.calculate_country_soe_td(\n",
    "        r_soe[c], pop[c], gov[c], ss_init[c], ss_term[c], hh_td[c], prod_init[c],\n",
    "        gamma, Jhh[c][T-1:, T-1:], tol)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OstxgKUNbzfu"
   },
   "source": [
    "Export the transition path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "-v-mbS-u4kmP"
   },
   "outputs": [],
   "source": [
    "population = {c: pop[c].N for c in pop}\n",
    "pop_growth = {c: pop[c].n for c in pop}\n",
    "pop_working = {c: pop[c].N - pop[c].get_Nret(gov[c].rho) for c in pop}\n",
    "\n",
    "paths = ({'r': r, 'W_Y': W_Y, 'NFA_Y': NFA_Y, 'K_Y': K_Y, 'Y': Y, 'PB_Y': PB_Y,\n",
    "          'C_Y': C_Y, 'Inc_Y': Inc_Y,'G_Y': G_Y, 'tau': tau, 'd_bar': d_bar,\n",
    "          'pop': population, 'pop_growth': pop_growth, 'pop_working': pop_working})\n",
    "if save_soe  or suffix == '_baseline' or (h_mult_scenario == 'All' and sigma == 2):\n",
    "  paths.update({'r_soe': r_soe, 'W_Y_soe': W_Y_soe, 'NFA_Y_soe': NFA_Y_soe,\n",
    "                'K_Y_soe': K_Y_soe, 'Y_soe': Y_soe, 'PB_Y_soe': PB_Y_soe,\n",
    "                'C_Y_soe': C_Y_soe, 'Inc_Y_soe': Inc_Y_soe,'G_Y_soe': G_Y_soe,\n",
    "                'tau_soe': tau_soe, 'd_bar_soe': d_bar_soe})\n",
    "\n",
    "suffix = '_mig' if migration is True else ''\n",
    "suffix += '_autarky' if closed_economy is not None else ''\n",
    "suffix += '_' + h_mult_scenario.replace(\" \", \"_\") if h_mult_scenario != 'Baseline' else ''\n",
    "suffix += '_FLFP' + str(FLFP_gap) if FLFP_gap is not None else ''\n",
    "suffix += f\"_{fertility_scenario}\" if fertility_scenario != \"medium\" else \"\"\n",
    "suffix += '_altdebt' if alt_debt is True else ''\n",
    "suffix += '_altret' if alt_ret is True else ''\n",
    "suffix += '_vintage_UNPP' if vintage_UNPP is True else ''\n",
    "suffix += f\"_{LIC_integration}_integration\" if LIC_integration != \"baseline\" else ''\n",
    "suffix += '_baseline' if suffix == '' else ''\n",
    "suffix += f'_IES{sigma}' if sigma != 2 else ''\n",
    "\n",
    "pickle.dump(paths, open(f'@Import/Data/cached_results/paths{suffix}.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsVxNLxeV5FF"
   },
   "source": [
    "# Generate Model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "3lVwz36oeCqU"
   },
   "outputs": [],
   "source": [
    "# Load model output data and append the historical data sets\n",
    "paths_here = pickle.load(open(f'@Import/Data/cached_results/paths{suffix}.pkl', 'rb'))\n",
    "paths = copy.deepcopy(paths_here)\n",
    "cs = list(paths_here['Y'].keys())\n",
    "\n",
    "if type(paths['r']) != dict:\n",
    "  # Add the exogenous wedge path for LIC back to the LIC interest rate\n",
    "  # Define the range of years\n",
    "  start_year = 2016\n",
    "  end_year = 2075\n",
    "  final_year = 2400\n",
    "\n",
    "  # Create an array of target years\n",
    "  target_years = np.arange(start_year, final_year + 1)\n",
    "\n",
    "  # A wedge that declines linearly to 0\n",
    "  interpolated_rates = np.where(\n",
    "      (target_years >= start_year) & (target_years <= end_year),\n",
    "      LIC_wedge - LIC_wedge * (target_years - start_year) / (end_year - start_year),\n",
    "      0,\n",
    "  )\n",
    "\n",
    "  # Add the wedge if running an integrated economy scenario\n",
    "  if closed_economy is None:\n",
    "    paths['r'] = ({c: paths['r'] if c not in ('LIC','CHN','IND') else\n",
    "                            paths['r'] + interpolated_rates for c in cs})\n",
    "  else:\n",
    "    paths['r'] = {c: paths['r'] for c in cs}\n",
    "\n",
    "# Create DataFrame to be exported\n",
    "df = pd.DataFrame()\n",
    "var_list = ['r','Y','NFA_Y','PB_Y','G_Y','C_Y','Inc_Y','tau','d_bar','pop','pop_growth','pop_working']\n",
    "if \"r_soe\" in paths:\n",
    "  var_list = np.append(var_list,['r_soe','Y_soe','PB_Y_soe'])\n",
    "\n",
    "for var in var_list:\n",
    "    df_var = pd.DataFrame()  # Initialize DataFrame for the current variable\n",
    "    for c in cs:  # Iterate through countries\n",
    "        # Convert data to Series, create DataFrame, and add country code\n",
    "        df_c = pd.DataFrame({'isocode': c,\n",
    "                            'year': range(2016, 2016 + len(paths[var][c])),\n",
    "                            var: paths[var][c]\n",
    "                            })\n",
    "        df_var = pd.concat([df_var, df_c], ignore_index=True)  # Append to variable's DataFrame\n",
    "\n",
    "    # if var == 'NFA_Y':\n",
    "    #     df_var = pd.concat([df_var, NFA_Y_hist], ignore_index=True)  # Add historical data for NFA_Y\n",
    "\n",
    "    df = df.merge(df_var, on=['isocode', 'year'], how='outer') if not df.empty else df_var  # Merge into main DataFrame\n",
    "\n",
    "# Save in the @Export folder\n",
    "df_all = df.sort_values(by=['isocode', 'year'])\n",
    "#df_all = pd.merge(df_all,pop_hist,on=['isocode','year'],how='outer')\n",
    "if closed_economy is not None:\n",
    "  df_all = df_all[df_all['isocode'] == closed_economy]\n",
    "df_all.to_csv(\"Data/\" + f\"{suffix}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "name": "",
   "provenance": [
    {
     "file_id": "1UZXgX4y9-mT2NwjZZchIXrGzGRyVgcLI",
     "timestamp": 1736370672943
    }
   ],
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
